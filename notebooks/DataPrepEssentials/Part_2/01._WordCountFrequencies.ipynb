{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.2.post1'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = [\"The Curse of the Cheese Pyramid. \",\n",
    "              \"The Hunt for the Golden Book. \",\n",
    "              \"The Temple of the Ruby of Fire. \",\n",
    "              \"Harry Potter and the Prisoner of Azkaban. \",\n",
    "              \"Harry Potter and the Goblet of Fire. \",\n",
    "              \"Harry Potter and the Order of the Phoenix. \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Represent text using the bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "count_vectorizer.fit(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the words in the vocabulary processed from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'azkaban',\n",
       " 'book',\n",
       " 'cheese',\n",
       " 'curse',\n",
       " 'fire',\n",
       " 'for',\n",
       " 'goblet',\n",
       " 'golden',\n",
       " 'harry',\n",
       " 'hunt',\n",
       " 'of',\n",
       " 'order',\n",
       " 'phoenix',\n",
       " 'potter',\n",
       " 'prisoner',\n",
       " 'pyramid',\n",
       " 'ruby',\n",
       " 'temple',\n",
       " 'the']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The unique identifiers for each word in the vocabulary\n",
    "\n",
    "Notice that they are all in lowercase, this is a part of the default preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 19,\n",
       " 'curse': 4,\n",
       " 'of': 11,\n",
       " 'cheese': 3,\n",
       " 'pyramid': 16,\n",
       " 'hunt': 10,\n",
       " 'for': 6,\n",
       " 'golden': 8,\n",
       " 'book': 2,\n",
       " 'temple': 18,\n",
       " 'ruby': 17,\n",
       " 'fire': 5,\n",
       " 'harry': 9,\n",
       " 'potter': 14,\n",
       " 'and': 0,\n",
       " 'prisoner': 15,\n",
       " 'azkaban': 1,\n",
       " 'goblet': 7,\n",
       " 'order': 12,\n",
       " 'phoenix': 13}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_.get(\"azkaban\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Curse of the Cheese Pyramid. ',\n",
       " 'The Hunt for the Golden Book. ',\n",
       " 'The Temple of the Ruby of Fire. ',\n",
       " 'Harry Potter and the Prisoner of Azkaban. ',\n",
       " 'Harry Potter and the Goblet of Fire. ',\n",
       " 'Harry Potter and the Order of the Phoenix. ']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of feature vectors\n",
    "\n",
    "- 6 sentences\n",
    "- 20 words in the vocabulary\n",
    "- counts of each word in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 20)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_vector = count_vectorizer.transform(train_text)\n",
    "\n",
    "transformed_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 2],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = [\"Harry Potter and the Chamber of Secrets. \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All words in the test text are not present in our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.transform(test_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit(train_text + test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 21,\n",
       " 'curse': 5,\n",
       " 'of': 12,\n",
       " 'cheese': 4,\n",
       " 'pyramid': 17,\n",
       " 'hunt': 11,\n",
       " 'for': 7,\n",
       " 'golden': 9,\n",
       " 'book': 2,\n",
       " 'temple': 20,\n",
       " 'ruby': 18,\n",
       " 'fire': 6,\n",
       " 'harry': 10,\n",
       " 'potter': 15,\n",
       " 'and': 0,\n",
       " 'prisoner': 16,\n",
       " 'azkaban': 1,\n",
       " 'goblet': 8,\n",
       " 'order': 13,\n",
       " 'phoenix': 14,\n",
       " 'chamber': 3,\n",
       " 'secrets': 19}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.transform(test_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"A Fabulous School Adventure\",\n",
    "        \"Diary of an Awesomely Friendly Kid\",\n",
    "        \"The Hunt for the Hundredth Key\",\n",
    "        \"Harry Potter and the Half-Blood Prince\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse matrix\n",
    "\n",
    "The actual transformed matrix is actually a sparse matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x22 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_vector = count_vectorizer.transform(text)\n",
    "\n",
    "transformed_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 12)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 21)\t2\n",
      "  (3, 0)\t1\n",
      "  (3, 10)\t1\n",
      "  (3, 15)\t1\n",
      "  (3, 21)\t1\n"
     ]
    }
   ],
   "source": [
    "print(transformed_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 22)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/harrypotter.txt\", \"r\") as f:\n",
    "    file_contents = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearly ten years had passed since the Dursleys had woken up to find their nephew on the front step, but Privet Drive had hardly changed at all. The sun rose on the same tidy front gardens and lit up the brass number four on the Dursleys' front door; it crept into their living room, which was almost exactly the same as it had been on the night when Mr. Dursley had seen that fateful news report about the owls. Only the photographs on the mantelpiece really showed how much time had passed. Ten years ago, there had been lots of pictures of what looked like a large pink beach ball wearing different-colored bonnets - but Dudley Dursley was no longer a baby, and now the photographs showed a large blond boy riding his first bicycle, on a carousel at the fair, playing a computer game with his father, being hugged and kissed by his mother. The room held no sign at all that another boy lived in the house, too.\n"
     ]
    }
   ],
   "source": [
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nearly ten years had passed since the Dursleys had woken up to find their nephew on the front step, but Privet Drive had hardly changed at all', \" The sun rose on the same tidy front gardens and lit up the brass number four on the Dursleys' front door; it crept into their living room, which was almost exactly the same as it had been on the night when Mr\", ' Dursley had seen that fateful news report about the owls', ' Only the photographs on the mantelpiece really showed how much time had passed', ' Ten years ago, there had been lots of pictures of what looked like a large pink beach ball wearing different-colored bonnets - but Dudley Dursley was no longer a baby, and now the photographs showed a large blond boy riding his first bicycle, on a carousel at the fair, playing a computer game with his father, being hugged and kissed by his mother', ' The room held no sign at all that another boy lived in the house, too', '']\n"
     ]
    }
   ],
   "source": [
    "sentences = file_contents.split(\".\")\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 111)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_vector = count_vectorizer.fit_transform(sentences)\n",
    "\n",
    "transformed_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 64)\t1\n",
      "  (0, 93)\t1\n",
      "  (0, 110)\t1\n",
      "  (0, 41)\t3\n",
      "  (0, 75)\t1\n",
      "  (0, 90)\t1\n",
      "  (0, 95)\t2\n",
      "  (0, 30)\t1\n",
      "  (0, 109)\t1\n",
      "  (0, 102)\t1\n",
      "  (0, 100)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 96)\t1\n",
      "  (0, 65)\t1\n",
      "  (0, 72)\t1\n",
      "  (0, 38)\t1\n",
      "  (0, 91)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 80)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 42)\t1\n",
      "  (0, 21)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 41)\t1\n",
      "  :\t:\n",
      "  (4, 32)\t1\n",
      "  (4, 79)\t1\n",
      "  (4, 23)\t1\n",
      "  (4, 39)\t1\n",
      "  (4, 108)\t1\n",
      "  (4, 34)\t1\n",
      "  (4, 12)\t1\n",
      "  (4, 47)\t1\n",
      "  (4, 51)\t1\n",
      "  (4, 19)\t1\n",
      "  (4, 61)\t1\n",
      "  (5, 95)\t2\n",
      "  (5, 7)\t1\n",
      "  (5, 2)\t1\n",
      "  (5, 84)\t1\n",
      "  (5, 94)\t1\n",
      "  (5, 68)\t1\n",
      "  (5, 16)\t1\n",
      "  (5, 43)\t1\n",
      "  (5, 89)\t1\n",
      "  (5, 5)\t1\n",
      "  (5, 55)\t1\n",
      "  (5, 48)\t1\n",
      "  (5, 45)\t1\n",
      "  (5, 101)\t1\n"
     ]
    }
   ],
   "source": [
    "print(transformed_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nearly': 64, 'ten': 93, 'years': 110, 'had': 41, 'passed': 75, 'since': 90, 'the': 95, 'dursleys': 30, 'woken': 109, 'up': 102, 'to': 100, 'find': 35, 'their': 96, 'nephew': 65, 'on': 72, 'front': 38, 'step': 91, 'but': 18, 'privet': 80, 'drive': 27, 'hardly': 42, 'changed': 21, 'at': 7, 'all': 2, 'sun': 92, 'rose': 85, 'same': 86, 'tidy': 98, 'gardens': 40, 'and': 4, 'lit': 54, 'brass': 17, 'number': 70, 'four': 37, 'door': 26, 'it': 50, 'crept': 24, 'into': 49, 'living': 56, 'room': 84, 'which': 107, 'was': 103, 'almost': 3, 'exactly': 31, 'as': 6, 'been': 11, 'night': 67, 'when': 106, 'mr': 62, 'dursley': 29, 'seen': 87, 'that': 94, 'fateful': 33, 'news': 66, 'report': 82, 'about': 0, 'owls': 74, 'only': 73, 'photographs': 76, 'mantelpiece': 60, 'really': 81, 'showed': 88, 'how': 46, 'much': 63, 'time': 99, 'ago': 1, 'there': 97, 'lots': 59, 'of': 71, 'pictures': 77, 'what': 105, 'looked': 58, 'like': 53, 'large': 52, 'pink': 78, 'beach': 10, 'ball': 9, 'wearing': 104, 'different': 25, 'colored': 22, 'bonnets': 15, 'dudley': 28, 'no': 68, 'longer': 57, 'baby': 8, 'now': 69, 'blond': 14, 'boy': 16, 'riding': 83, 'his': 44, 'first': 36, 'bicycle': 13, 'carousel': 20, 'fair': 32, 'playing': 79, 'computer': 23, 'game': 39, 'with': 108, 'father': 34, 'being': 12, 'hugged': 47, 'kissed': 51, 'by': 19, 'mother': 61, 'held': 43, 'sign': 89, 'another': 5, 'lived': 55, 'in': 48, 'house': 45, 'too': 101}\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructs the original sentences\n",
    "\n",
    "We have lost the ordering of the words, so the sentences may not be well-formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['nearly', 'ten', 'years', 'had', 'passed', 'since', 'the',\n",
       "        'dursleys', 'woken', 'up', 'to', 'find', 'their', 'nephew', 'on',\n",
       "        'front', 'step', 'but', 'privet', 'drive', 'hardly', 'changed',\n",
       "        'at', 'all'], dtype='<U11'),\n",
       " array(['had', 'the', 'dursleys', 'up', 'their', 'on', 'front', 'sun',\n",
       "        'rose', 'same', 'tidy', 'gardens', 'and', 'lit', 'brass', 'number',\n",
       "        'four', 'door', 'it', 'crept', 'into', 'living', 'room', 'which',\n",
       "        'was', 'almost', 'exactly', 'as', 'been', 'night', 'when', 'mr'],\n",
       "       dtype='<U11'),\n",
       " array(['had', 'the', 'dursley', 'seen', 'that', 'fateful', 'news',\n",
       "        'report', 'about', 'owls'], dtype='<U11'),\n",
       " array(['had', 'passed', 'the', 'on', 'only', 'photographs', 'mantelpiece',\n",
       "        'really', 'showed', 'how', 'much', 'time'], dtype='<U11'),\n",
       " array(['ten', 'years', 'had', 'the', 'on', 'but', 'at', 'and', 'was',\n",
       "        'been', 'dursley', 'photographs', 'showed', 'ago', 'there', 'lots',\n",
       "        'of', 'pictures', 'what', 'looked', 'like', 'large', 'pink',\n",
       "        'beach', 'ball', 'wearing', 'different', 'colored', 'bonnets',\n",
       "        'dudley', 'no', 'longer', 'baby', 'now', 'blond', 'boy', 'riding',\n",
       "        'his', 'first', 'bicycle', 'carousel', 'fair', 'playing',\n",
       "        'computer', 'game', 'with', 'father', 'being', 'hugged', 'kissed',\n",
       "        'by', 'mother'], dtype='<U11'),\n",
       " array(['the', 'at', 'all', 'room', 'that', 'no', 'boy', 'held', 'sign',\n",
       "        'another', 'lived', 'in', 'house', 'too'], dtype='<U11'),\n",
       " array([], dtype='<U11')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.inverse_transform(transformed_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

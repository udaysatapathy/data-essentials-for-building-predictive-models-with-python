{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = [\"The Curse of the Cheese Pyramid. \",\n",
    "              \"The Hunt for the Golden Book. \",\n",
    "              \"The Temple of the Ruby of Fire. \",\n",
    "              \"Harry Potter and the Prisoner of Azkaban. \",\n",
    "              \"Harry Potter and the Goblet of Fire. \",\n",
    "              \"Harry Potter and the Order of the Phoenix. \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the term frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "frequency_term_matrix = count_vectorizer.fit_transform(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 19,\n",
       " 'curse': 4,\n",
       " 'of': 11,\n",
       " 'cheese': 3,\n",
       " 'pyramid': 16,\n",
       " 'hunt': 10,\n",
       " 'for': 6,\n",
       " 'golden': 8,\n",
       " 'book': 2,\n",
       " 'temple': 18,\n",
       " 'ruby': 17,\n",
       " 'fire': 5,\n",
       " 'harry': 9,\n",
       " 'potter': 14,\n",
       " 'and': 0,\n",
       " 'prisoner': 15,\n",
       " 'azkaban': 1,\n",
       " 'goblet': 7,\n",
       " 'order': 12,\n",
       " 'phoenix': 13}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_term_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 2],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_term_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The TfidfTransformer\n",
    "\n",
    "Converts a term frequency matrix to a Tf-IDF representation of words in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "tfidf_vector1 = tfidf_transformer.fit_transform(frequency_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 20)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency, Inverse Document Frequency\n",
    "\n",
    "- Upweigh words which are present more often in a single sentence\n",
    "- Downweigh words which are common across the document corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.49686319, 0.49686319,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25455629, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.49686319, 0.        , 0.        , 0.44111449],\n",
       "       [0.        , 0.        , 0.45699818, 0.        , 0.        ,\n",
       "        0.        , 0.45699818, 0.        , 0.45699818, 0.        ,\n",
       "        0.45699818, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.40572238],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3861072 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.48246241, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.47085422, 0.47085422, 0.41802376],\n",
       "       [0.35068227, 0.5065376 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.35068227,\n",
       "        0.        , 0.25951275, 0.        , 0.        , 0.35068227,\n",
       "        0.5065376 , 0.        , 0.        , 0.        , 0.22485171],\n",
       "       [0.36641889, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.43400743, 0.        , 0.52926812, 0.        , 0.36641889,\n",
       "        0.        , 0.2711582 , 0.        , 0.        , 0.36641889,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.23494177],\n",
       "       [0.32677503, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.32677503,\n",
       "        0.        , 0.24182086, 0.47200515, 0.47200515, 0.32677503,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.41904556]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 19,\n",
       " 'curse': 4,\n",
       " 'of': 11,\n",
       " 'cheese': 3,\n",
       " 'pyramid': 16,\n",
       " 'hunt': 10,\n",
       " 'for': 6,\n",
       " 'golden': 8,\n",
       " 'book': 2,\n",
       " 'temple': 18,\n",
       " 'ruby': 17,\n",
       " 'fire': 5,\n",
       " 'harry': 9,\n",
       " 'potter': 14,\n",
       " 'and': 0,\n",
       " 'prisoner': 15,\n",
       " 'azkaban': 1,\n",
       " 'goblet': 7,\n",
       " 'order': 12,\n",
       " 'phoenix': 13}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_vector2 = tfidf_vectorizer.fit_transform(train_text)\n",
    "\n",
    "tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 20)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.55961579, 2.25276297, 2.25276297, 2.25276297, 2.25276297,\n",
       "       1.84729786, 2.25276297, 2.25276297, 2.25276297, 1.55961579,\n",
       "       2.25276297, 1.15415068, 2.25276297, 2.25276297, 1.55961579,\n",
       "       2.25276297, 2.25276297, 2.25276297, 2.25276297, 1.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping words and IDF scores\n",
    "\n",
    "The IDF scores of more common words are lower that less common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 1.5596157879354227,\n",
       " 'azkaban': 2.252762968495368,\n",
       " 'book': 2.252762968495368,\n",
       " 'cheese': 2.252762968495368,\n",
       " 'curse': 2.252762968495368,\n",
       " 'fire': 1.8472978603872037,\n",
       " 'for': 2.252762968495368,\n",
       " 'goblet': 2.252762968495368,\n",
       " 'golden': 2.252762968495368,\n",
       " 'harry': 1.5596157879354227,\n",
       " 'hunt': 2.252762968495368,\n",
       " 'of': 1.1541506798272583,\n",
       " 'order': 2.252762968495368,\n",
       " 'phoenix': 2.252762968495368,\n",
       " 'potter': 1.5596157879354227,\n",
       " 'prisoner': 2.252762968495368,\n",
       " 'pyramid': 2.252762968495368,\n",
       " 'ruby': 2.252762968495368,\n",
       " 'temple': 2.252762968495368,\n",
       " 'the': 1.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t0.4968631937710093\n",
      "  (0, 3)\t0.4968631937710093\n",
      "  (0, 11)\t0.2545562941559567\n",
      "  (0, 4)\t0.4968631937710093\n",
      "  (0, 19)\t0.44111448982390433\n",
      "  (1, 2)\t0.4569981804131008\n",
      "  (1, 8)\t0.4569981804131008\n",
      "  (1, 6)\t0.4569981804131008\n",
      "  (1, 10)\t0.4569981804131008\n",
      "  (1, 19)\t0.40572238340577144\n",
      "  (2, 5)\t0.3861071975850641\n",
      "  (2, 17)\t0.4708542218561549\n",
      "  (2, 18)\t0.4708542218561549\n",
      "  (2, 11)\t0.48246240537039725\n",
      "  (2, 19)\t0.41802375877178133\n",
      "  (3, 1)\t0.5065375978836059\n",
      "  (3, 15)\t0.5065375978836059\n",
      "  (3, 0)\t0.3506822714552184\n",
      "  (3, 14)\t0.3506822714552184\n",
      "  (3, 9)\t0.3506822714552184\n",
      "  (3, 11)\t0.2595127499569568\n",
      "  (3, 19)\t0.2248517065343652\n",
      "  (4, 7)\t0.5292681154550154\n",
      "  (4, 0)\t0.3664188911387316\n",
      "  (4, 14)\t0.3664188911387316\n",
      "  (4, 9)\t0.3664188911387316\n",
      "  (4, 5)\t0.43400742595846153\n",
      "  (4, 11)\t0.27115820164217774\n",
      "  (4, 19)\t0.23494176833371702\n",
      "  (5, 13)\t0.47200515447423746\n",
      "  (5, 12)\t0.47200515447423746\n",
      "  (5, 0)\t0.32677503190519636\n",
      "  (5, 14)\t0.32677503190519636\n",
      "  (5, 9)\t0.32677503190519636\n",
      "  (5, 11)\t0.24182085622717006\n",
      "  (5, 19)\t0.4190455552361038\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 19)\t0.44111448982390433\n",
      "  (0, 16)\t0.4968631937710093\n",
      "  (0, 11)\t0.2545562941559567\n",
      "  (0, 4)\t0.4968631937710093\n",
      "  (0, 3)\t0.4968631937710093\n",
      "  (1, 19)\t0.40572238340577144\n",
      "  (1, 10)\t0.4569981804131008\n",
      "  (1, 8)\t0.4569981804131008\n",
      "  (1, 6)\t0.4569981804131008\n",
      "  (1, 2)\t0.4569981804131008\n",
      "  (2, 19)\t0.41802375877178133\n",
      "  (2, 18)\t0.4708542218561549\n",
      "  (2, 17)\t0.4708542218561549\n",
      "  (2, 11)\t0.48246240537039725\n",
      "  (2, 5)\t0.3861071975850641\n",
      "  (3, 19)\t0.2248517065343652\n",
      "  (3, 15)\t0.5065375978836059\n",
      "  (3, 14)\t0.3506822714552184\n",
      "  (3, 11)\t0.2595127499569568\n",
      "  (3, 9)\t0.3506822714552184\n",
      "  (3, 1)\t0.5065375978836059\n",
      "  (3, 0)\t0.3506822714552184\n",
      "  (4, 19)\t0.23494176833371708\n",
      "  (4, 14)\t0.36641889113873166\n",
      "  (4, 11)\t0.2711582016421778\n",
      "  (4, 9)\t0.36641889113873166\n",
      "  (4, 7)\t0.5292681154550155\n",
      "  (4, 5)\t0.43400742595846165\n",
      "  (4, 0)\t0.36641889113873166\n",
      "  (5, 19)\t0.4190455552361038\n",
      "  (5, 14)\t0.32677503190519636\n",
      "  (5, 13)\t0.47200515447423746\n",
      "  (5, 12)\t0.47200515447423746\n",
      "  (5, 11)\t0.24182085622717006\n",
      "  (5, 9)\t0.32677503190519636\n",
      "  (5, 0)\t0.32677503190519636\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
